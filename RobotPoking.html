<!DOCTYPE html>

<!-- Ref:http://vpg.cs.princeton.edu/ -->


<html class="no-js" lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Semi-Empirical Simulation of Learned Force Response Models for Heterogeneous Elastic Objects</title>
	<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	<link rel="icon" href="favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,900" rel="stylesheet">
    <link rel="stylesheet" href="libs/font-awesome/css/font-awesome.min.css">
    <!--??-->
    <link href="css/project.css" rel="stylesheet">
</head>

<body>

    <div id="main" style="padding-bottom:1em; padding-top: 5em; width: 60em; max-width: 70em; margin-left: auto; margin-right: auto;">
        <section id="four">
            <h1 style="text-align: center; margin-bottom: 0;">
                Semi-Empirical Simulation of Learned Force Response Models
            </h1>
            <h2 style="text-align: center;"> for Heterogeneous Elastic Objects</h2>
            <br>
            <section>
                <div class="box alt" style="margin-bottom: 1em;">
                    <h5 style="text-align: center;">      
                            Yifan Zhu<sup>1</sup>, 
                            Kai Lu<sup>2</sup>, 
                            Kris Hauser<sup>1</sup>
                </div>
            </section>


            <h6 style="color: #a2a2a2; margin-bottom: 2em;">
                <sup>1</sup> Y. Zhu and K. Hauser are with the Departments of Computer Science, University of Illinois at Urbana-Champaign, IL, USA.
                {yifan16, kkhauser}@illinois.edu}<br>
                <sup>2</sup> K. Lu is with the Department of Automation, Tsinghua University, Beijing, China.
                {lu-k16@mails.tsinghua.edu.cn}<br>
            </h6>

            <hr>
            <br>
            <b><h2 style="text-align: center;">Abstract</h2></b>

            <p>
                This paper presents a semi-empirical method for simulating contact with 
                elastically deformable objects whose force response is learned using entirely data-driven models.  
                A point-based surface representation and inhomogeneous, nonlinear force response model are learned 
                from a robotic arm acquiring force-displacement curves from a small number of poking interactions.  
                The simulator then estimates displacement and force response when the deformable object is in contact 
                with an arbitrary rigid object. It does so by summing the expected forces at individual points through 
                querying the learned point stiffness models as a function of their expected displacement. Experiments 
                on a variety of challenging objects show that our approach learns force response with sufficient 
                accuracy to generate plausible contact response for novel rigid objects.
            </p>
            
            <div class="box alt">
                <div class="row 50% uniform">
                    <!--div class="6u"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="1">
                        <source src="images/RobotGrasping/grasp1.mp4" type="video/mp4">Your browser does not support this video.</video>
                    </div-->
                    <div class="6u"><a href=""><span class="image fit" style="margin-bottom: 0.5em;" controls="">
                        <img src="images/RobotPoking/system_all.png" alt=""></span></a></div>
                    
                    <div class="6u$"><a href=""><span class="image fit" style="margin-bottom: 0.5em;" controls="">
                        <img src="images/RobotPoking/poking_video.png" alt=""></span></a></div>

                    <!--div class="6u$"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="2">
                        <source src="images/RobotPoking/poking_video.png" type="video/mp4">Your browser does not support this video.</video-->
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>            
                </div>
            </div>

            <!--div class="12u$"><a href=""><span class="image fit"><img src="images/RobotPoking/system_all.png" alt=""></span></a></div-->

            <p><i>Our Poking System</i> gathered data using the point probe, 
                and the simulator generalizes force predictions to the line and cylinder probes. 
            </p> 

            <hr>

            
            <b><h2 style="text-align: center;">Summary Video</h2></b>
            <div class="12u$">
                <a href=""><span class="image fit"><img src="images/RobotPoking/summary_video.png" alt=""></span></a>
            </div>

            <!--div class="12u$">
                <video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="0">
                    <source src="images/RobotGrasping/main.mp4" type="video/mp4">Your browser does not support this video.
                    </video>
                </div-->
            <hr>
            
            <b><h2 style="text-align: center;">Workflow</h2></b>

            <div class="12u$"><a href=""><span class="image fit"><img src="images/RobotPoking/workflow.png" alt=""></span></a></div>

            <p>
                The flow of our overall system is illustrated in the aboved image.  The first stage of our system 
                learns a visuo-tactile  model of the deformable object using data. We shall discuss the learning 
                stage in the current section, leaving the discussion of simulation for Section IV.  We assume that 
                the object is elastic, quasistatic, and that interaction forces are dominated by normal deformation 
                rather than friction and shear deformation.  We hope to relax these assumptions in future work. 
            </p>

            <hr>
            <b><h2 style="text-align: center;">Example Results</h2></b>
            <h3>Characteristics of Grasp Process</h3>
            <p>Compared with other suction grasping systems, 
                the proposed composite robotic hand uses the two fingers to hold the
                object after the suction cup lifts the object, which increases the stability of the grasp:
            </p>

            <div class="box alt">
                <div class="row 50% uniform">
                    <div class="6u"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="1">
                        <source src="images/RobotGrasping/grasp1.mp4" type="video/mp4">Your browser does not support this video.</video>
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>
                    <div class="6u$"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="2">
                        <source src="images/RobotGrasping/grasp2.mp4" type="video/mp4">Your browser does not support this video.</video>
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>            
                </div>
            </div>

            <!-- <h6 style="color: #a2a2a2; margin-bottom: 2em;">Note:</h6> -->

            <h3>Robotic Experiments(Simulation)</h3>
            <p>We test our DQN model on real environment, including a Microsoftâ€™s Kinect V2 camera as the image acquisition tool
                to get the RGB image and depth image of the scene and a UR5 manipulator to carry our composite robotic hand.
                We select 40 different objects to build different scenes for our robotic hand to grasp.
            </p>

            <div class="box alt">
                <div class="row 50% uniform">
                    <div class="6u"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="3">
                        <source src="images/RobotGrasping/push1.mp4" type="video/mp4">Your browser does not support this video.</video>
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>
                    <div class="6u$"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="4">
                        <source src="images/RobotGrasping/push2.mp4" type="video/mp4">Your browser does not support this video.</video>
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>
                    <div class="6u"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="5">
                        <source src="images/RobotGrasping/push3.mp4" type="video/mp4">Your browser does not support this video.</video>
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>
                    <div class="6u$"><video class="image fit" style="margin-bottom: 0.5em;" controls="" data-video="6">
                        <source src="images/RobotGrasping/push4.mp4" type="video/mp4">Your browser does not support this video.</video>
                        <!-- <h5 style="color: #a2a2a2; margin-bottom: 1em;">Total # of actions: 7 (task complete)</h5> -->
                    </div>  
                </div>
            </div>

            <!-- Add a container including four videos in it -->
            <!-- <div class="box alt">
                <div class="row 50% uniform">
                    <div class="6u"><video class="image fit" controls="" data-video="9"><source src="images/videos/test-vpg-novel-04.mp4" type="video/mp4">Your browser does not support this video.</video></div>
                    <div class="6u$"><video class="image fit" controls="" data-video="10"><source src="images/videos/test-vpg-novel-02.mp4" type="video/mp4">Your browser does not support this video.</video></div>
                    <div class="6u"><video class="image fit" controls="" data-video="11"><source src="images/videos/test-vpg-novel-01.mp4" type="video/mp4">Your browser does not support this video.</video></div>
                    <div class="6u$"><video class="image fit" controls="" data-video="12"><source src="images/videos/test-vpg-novel-03.mp4" type="video/mp4">Your browser does not support this video.</video></div>
                </div>
            </div> -->

            <!-- <p style="margin-bottom: 1em;">For more quantitative evaluations and ablation studies (in both simulation and real-world settings), please check out our <a href="https://arxiv.org/abs/1803.09956">technical report</a>. There, we also explore some interesting questions like:
            </p>
            <ul>
                <li>Is it possible to train pushing policies without any rewards? Can intrinsic rewards help?</li>
                <li>Does long-term lookahead matter for planning VPG strategies in picking?</li>
                <li>Is it possible to train VPG policies without ImageNet pre-training? How much do pre-trained weights influence sample complexity and performance?</li>
                <li>Can we train VPG policies with only color information (no depth/height-from-bottom information)?</li>
            </ul> -->

            <!-- <h4>Failure Modes</h4> -->

            <!-- <div class="box alt">
                <div class="row 50% uniform">
                    <div class="6u"><video class="image fit" controls="" data-video="13"><source src="images/videos/test-vpg-novel-05.mp4" type="video/mp4">Your browser does not support this video.</video></div>
                    <div class="6u$"><video class="image fit" controls="" data-video="14"><source src="images/videos/test-vpg-blocks-02.mp4" type="video/mp4">Your browser does not support this video.</video></div>
                </div>
            </div> -->

            <hr>
            <b><h3>Contact</h3></b>
            <p>Have any questions, please feel free to contact <a href="https://DeerKK.github.io/">Kai Lu</a></p>
            <hr>

            <div class="row">
                <div class="6u 12u$(xsmall)">
                    <p>March 19, 2019<br>
                        Copyright &copy; <a href="https://DeerKK.github.io/">Kai Lu</a>
                    </p>
                </div>
                <!-- Share the website -->
                <!-- <div class="6u$ 12u$(xsmall)" style="text-align: right;">
                    <ul class="icons"><li><a href="https://twitter.com/intent/tweet?text=Learning%20Synergies%20between%20Pushing%20and%20Grasping%20with%20Self-supervised Deep%20Reinforcement%20Learning%20http://vpg.cs.princeton.edu" class="icon fa-twitter"><span class="label">Twitter</span>&nbsp;Tweet</a></li>&nbsp;&nbsp;&nbsp;&nbsp;<li><a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fvpg.cs.princeton.edu%2F" class="icon fa-facebook-square"><span class="label">Facebook</span>&nbsp;&nbsp;Share</a></li></ul>
                    <ul class="icons"></ul>
                </div> -->
            </div>
        </section>
    </div>

    <!-- Copyright -->
    <!-- <footer id="footer">
            <div class="inner">
                <ul class="copyright">
                    <p>Copyright &copy; 2019 Yixuan Wei</p>
                </ul>
            </div>
        </footer> -->

    <script src="js/project/main.js"></script>
    <script src="js/project/util.js"></script>
    <script src="js/project/skel.min.js"></script>
    <script src="js/project/jquery.min.js"></script>
    <script src="js/project/jquery.poptrox.min.js"></script>
</body>

</html>
